{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# ## Load Packages\n",
        "\n",
        "# In[1]:\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.layers import Dense, Bidirectional\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from pickle import dump\n",
        "\n",
        "\n",
        "# ## Import Data\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "df = pd.read_csv('../../data/merged_all_values_v2.csv')\n",
        "\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "\n",
        "df.head()\n",
        "\n",
        "\n",
        "# ## Take Subset Of Data To Only Include Years 2017, 2018, 2019 and 2020\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "\n",
        "df = df[(df.YEAR == 2018) | (df.YEAR == 2019) | (df.YEAR == 2020) | (df.YEAR == 2021)]\n",
        "\n",
        "# prepare the categoorical inputs with one hot encoding\n",
        "\n",
        "# ## One Hot Encoding\n",
        "\n",
        "# ### Month\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "month = pd.get_dummies(df.MONTH, prefix='MONTH')\n",
        "\n",
        "\n",
        "\n",
        "# ### Hour\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "\n",
        "hour = pd.get_dummies(df.HOUR, prefix='HOUR')\n",
        "\n",
        "# ## Scale Continuous Variables\n",
        "\n",
        "# ### Temperature\n",
        "\n",
        "# In[7]:\n",
        "temperature = pd.DataFrame();\n",
        "temperature['TEMPERATURE'] = df['TEMPERATURE']\n",
        "\n",
        "temp_transformer = MinMaxScaler(feature_range=(0, 1))\n",
        "temp_transformer = temp_transformer.fit(temperature[['TEMPERATURE']])\n",
        "temperature['TEMPERATURE'] = temp_transformer.transform(temperature[['TEMPERATURE']])\n",
        "\n",
        "\n",
        "# ### Total Demand\n",
        "\n",
        "# In[8]:\n",
        "demand = pd.DataFrame()\n",
        "demand['TOTALDEMAND'] = df['TOTALDEMAND']\n",
        "td_transformer = MinMaxScaler(feature_range=(0, 1))\n",
        "td_transformer = td_transformer.fit(demand[['TOTALDEMAND']])\n",
        "\n",
        "demand['TOTALDEMAND'] = td_transformer.transform(demand[['TOTALDEMAND']])\n",
        "\n",
        "# ## Prepare the Input Series - using separate variable, so that we can save the result with original timestamp\n",
        "\n",
        "# In[9]:\n",
        "X = pd.concat([df.YEAR, month, hour, df.WEEKEND, df.PUBLIC_HOLIDAY, temperature, demand ], axis=1)\n",
        "\n",
        "# ## Create Train and Test Datasets\n",
        "train = X[X.YEAR != 2021]\n",
        "test = X[X.YEAR == 2021]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[10]:\n",
        "# ## Drop Columns Not Required\n",
        "train.drop(['YEAR'], axis = 1, inplace= True)\n",
        "test.drop(['YEAR'], axis = 1, inplace= True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ## Configure Lookback Period And Apply To Train And Test Datasets\n",
        "\n",
        "# In[11]:\n",
        "\n",
        "\n",
        "def create_dataset(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        v = X.iloc[i:(i + time_steps)].values\n",
        "        Xs.append(v)        \n",
        "        ys.append(y.iloc[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "\n",
        "# In[12]:\n",
        "print(test.head())\n",
        "\n",
        "time_steps = 24\n",
        "\n",
        "# Prepare The Train And Test Sets\n",
        "\n",
        "X_train, y_train = create_dataset(train, train.TOTALDEMAND, time_steps)\n",
        "X_test, y_test = create_dataset(test, test.TOTALDEMAND, time_steps)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "# ## Configure LSTM Neural Network\n",
        "\n",
        "# In[13]:\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Bidirectional(LSTM(units=50, input_shape=(\n",
        "        X_train.shape[1],\n",
        "        X_train.shape[2]),\n",
        "         activation='relu')\n",
        "         ))\n",
        "\n",
        "\n",
        "model.add(Dense(1))\n",
        "opt = Adam()\n",
        "model.compile(loss='mean_squared_error', optimizer=opt)\n",
        "\n",
        "\n",
        "# ## Fit Model To Train Dataset\n",
        "\n",
        "# In[14]:\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.1, shuffle=True)\n",
        "\n",
        "# ## Plot Losses Per Epoch\n",
        "\n",
        "# In[15]:\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss Per Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ## Make Predictions For Test And Train Dataset\n",
        "\n",
        "# In[16]:\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_train = model.predict(X_train)\n",
        "\n",
        "\n",
        "# ## Convert Values Back To Regular Values\n",
        "\n",
        "# In[17]:\n",
        "\n",
        "\n",
        "# Typically you would not scale y values. However, as the scaled total demand values were used to create both the x and y\n",
        "# values, the scaling for the prediction and y test now needs to be reversed.\n",
        "y_pred = td_transformer.inverse_transform(y_pred)\n",
        "y_test = td_transformer.inverse_transform([y_test])\n",
        "\n",
        "y_pred_train = td_transformer.inverse_transform(y_pred_train)\n",
        "y_train = td_transformer.inverse_transform([y_train])\n",
        "\n",
        "\n",
        "# ## Calculate RMSE\n",
        "\n",
        "# ### Test Dataset\n",
        "\n",
        "# In[18]:\n",
        "\n",
        "\n",
        "y_test = y_test.reshape(-1)\n",
        "y_test = pd.Series(y_test)\n",
        "\n",
        "y_pred = y_pred.reshape(-1)\n",
        "y_pred = pd.Series(y_pred)\n",
        "\n",
        "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
        "\n",
        "print('Test RMSE: %f' % rmse)\n",
        "\n",
        "\n",
        "# ### Train Dataset (for comparison with Test dataset)\n",
        "\n",
        "# In[19]:\n",
        "\n",
        "\n",
        "y_train = y_train.reshape(-1)\n",
        "y_train = pd.Series(y_train)\n",
        "\n",
        "y_pred_train = y_pred_train.reshape(-1)\n",
        "y_pred_train = pd.Series(y_pred_train)\n",
        "\n",
        "rmse = mean_squared_error(y_train, y_pred_train, squared = False)\n",
        "\n",
        "print('Train RMSE: %f' % rmse)\n",
        "\n",
        "\n",
        "# ## Average Percentage Difference Between Prediction And Actual Values\n",
        "\n",
        "# In[20]:\n",
        "\n",
        "\n",
        "predict_actual = y_test.to_frame()\n",
        "predict_actual['PREDICTION'] = y_pred\n",
        "predict_actual.columns = ['ACTUAL', 'PREDICTION']\n",
        "predict_actual['PERCENT_DIFF'] = abs(predict_actual.ACTUAL - predict_actual.PREDICTION) / predict_actual.ACTUAL * 100\n",
        "\n",
        "\n",
        "# In[21]:\n",
        "\n",
        "\n",
        "avg_perc_diff = sum(predict_actual.PERCENT_DIFF) / len(predict_actual)\n",
        "print('Average Percentage Difference', avg_perc_diff)\n",
        "\n",
        "# ## Save The Result in a .csv with Timestamp, Temperature, Actual & Predicted Demand\n",
        "\n",
        "# In[22]:\n",
        "\n",
        "\n",
        "df = df[(df.YEAR == 2021)]\n",
        "\n",
        "# reset the index as it is a filtered set\n",
        "df.reset_index(drop=True, inplace=True) \n",
        "\n",
        "# drop the records used for the first prediction\n",
        "df.drop(range(0,time_steps), axis = 0, inplace=True) \n",
        "\n",
        "# reset the index as we dropped records.\n",
        "df.reset_index(drop=True, inplace=True) \n",
        "\n",
        "print(predict_actual.head())\n",
        "print(df.head())\n",
        "KeyData = ['DATETIME', 'TEMPERATURE', 'TOTALDEMAND']\n",
        "\n",
        "df_out = pd.concat([df[KeyData], predict_actual['PREDICTION']], axis=1)\n",
        "df_out['Percentage diff'] = 100 * (df_out['PREDICTION'] - df_out['TOTALDEMAND']) / df_out['TOTALDEMAND']\n",
        "print(df_out.head())\n",
        "df_out.to_csv('./output/LSTM_result.csv', index = False)\n",
        "\n",
        "# ## Save The Model AND Scalers\n",
        "# In[23]:\n",
        "\n",
        "# ### Save The Modle\n",
        "model.save('./output/LSTM_model.h5')  # creates a HDF5 file\n",
        "\n",
        "# ### Save The Scalers For Demand AND Temporarture\n",
        "dump(td_transformer, open('./output/scaler_td.pkl', 'wb'))\n",
        "dump(temp_transformer, open('./output/scaler_temperature.pkl', 'wb'))\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}